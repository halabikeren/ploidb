{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a9ae6ef-c475-492b-bf4d-4f328234a539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 20 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 20 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "from ete3 import Tree, TreeStyle\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from collections import Counter\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/groups/itay_mayrose/halabikeren/tmp/ploidb/data_processing/\")\n",
    "from check_tree_monophyly import add_group_by_property\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandarallel import pandarallel\n",
    "\n",
    "pandarallel.initialize(progress_bar=False)\n",
    "pallete = px.colors.qualitative.Vivid\n",
    "\n",
    "import plotly.io as pio\n",
    "\n",
    "pio.templates.default = \"plotly_white\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/groups/itay_mayrose/halabikeren/tmp/ploidb/\")\n",
    "from services.pbs_service import PBSService\n",
    "\n",
    "from pandarallel import pandarallel\n",
    "\n",
    "pandarallel.initialize(progress_bar=True, use_memory_fs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a4630c75-5875-4566-9540-625452b385db",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by_options = [\"genus\", \"family\"]\n",
    "tree_name = \"ALLMB\"  # or \"ALLOTB\"\n",
    "add_missing_names = False\n",
    "resolve_ccdb = False\n",
    "resolve_tree = False\n",
    "classification_path = \"../trees/wfo_classification_data.csv\"\n",
    "tree_path = f\"../trees/resolved_{tree_name}_name_resolution_on_{'ccdb_and_tree' if resolve_ccdb and resolve_tree else ('only_ccdb' if resolve_ccdb else 'none')}_with_added_ccdb_{'and_wo_counts_' if add_missing_names else ''}names.nwk\"\n",
    "classification_data = pd.read_csv(classification_path)\n",
    "time_points_to_partition_by = [5, 10, 20]\n",
    "nodes_distances_path = f\"./nodes_dist_{os.path.basename(tree_path).replace('nwk', 'csv')}\"\n",
    "time_points_to_partition_by_outpath = (\n",
    "    f\"../trees/time_points_to_internal_nodes_to_partition_by{'_with_missing_data' if add_missing_names else ''}.pkl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e07a730-5114-43f4-a22f-949a203043bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = Tree(tree_path, format=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36036e6-2711-4be1-9125-feade4f87413",
   "metadata": {},
   "source": [
    "## Partition by times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3b5fb92-70ae-4791-aa5d-fde07d6cbc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_relevant_desendents(node: Tree, dist_from_root: float, node_to_dist: dict) -> list[str]:\n",
    "    if node.is_leaf():\n",
    "        return []\n",
    "\n",
    "    if node.name != \"\" and node_to_dist[node.name] >= dist_from_root:\n",
    "        return [node.name]\n",
    "\n",
    "    desc = []\n",
    "    for child in node.get_children():\n",
    "        desc += get_relevant_desendents(node=child, dist_from_root=dist_from_root, node_to_dist=node_to_dist)\n",
    "    return desc\n",
    "\n",
    "\n",
    "def get_internal_nodes_to_partition_by(tree: Tree, node_to_dist: dict, time_point: int):\n",
    "    dist_from_root = tree.get_distance(tree.get_leaf_names()[0]) - time_point\n",
    "    print(f\"dist_from_root={dist_from_root} for time_point={time_point}\")\n",
    "    internal_nodes_to_parition_by = set(\n",
    "        get_relevant_desendents(node=tree, dist_from_root=dist_from_root, node_to_dist=node_to_dist)\n",
    "    )\n",
    "    for node_name in internal_nodes_to_parition_by:\n",
    "        node = tree.search_nodes(name=node_name)[0]\n",
    "        assert node.get_distance(node.get_leaves()[0]) <= dist_from_root\n",
    "    return list(internal_nodes_to_parition_by)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9eb9cd3c-bc84-4503-9241-c1c3a4934b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(nodes_distances_path):\n",
    "    nodes_distances = pd.DataFrame({\"node\": [node.name for node in tree.traverse()]})\n",
    "    print(f\"# nodes to compute distance for = {nodes_distances.shape[0]:,}\")\n",
    "    nodes_distances[\"distance_from_root\"] = nodes_distances.node.parallel_apply(lambda node: tree.get_distance(node))\n",
    "    nodes_distances.to_csv(f\"./nodes_dist_{os.path.basename(tree_path).replace('nwk', 'csv')}\", index=False)\n",
    "else:\n",
    "    nodes_distances = pd.read_csv(f\"./nodes_dist_{os.path.basename(tree_path).replace('nwk', 'csv')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3dedfe5c-74b8-40c2-89fb-066bef38b3fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce2b3b9e11314ddeb1232d9ee5b96928",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=1), Label(value='0 / 1'))), HBox(câ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dist_from_root=315.050124 for time_point=10\n",
      "dist_from_root=320.050124 for time_point=5\n",
      "dist_from_root=305.050124 for time_point=20\n",
      "# clades when partitioning by 5M years = 5541\n",
      "# clades when partitioning by 10M years = 4038\n",
      "# clades when partitioning by 20M years = 2329\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(time_points_to_partition_by_outpath):\n",
    "    with open(time_points_to_partition_by_outpath, \"rb\") as f:\n",
    "        time_point_to_internal_nodes_to_parition_by = pickle.load(f)\n",
    "else:\n",
    "    node_to_dist = nodes_distances.set_index(\"node\")[\"distance_from_root\"].to_dict()\n",
    "    time_point_to_internal_nodes_to_parition_by = pd.DataFrame({\"time_point\": time_points_to_partition_by})\n",
    "    time_point_to_internal_nodes_to_parition_by[\n",
    "        \"nodes_to_partition_by\"\n",
    "    ] = time_point_to_internal_nodes_to_parition_by.time_point.parallel_apply(\n",
    "        lambda time_point: get_internal_nodes_to_partition_by(\n",
    "            tree=tree, node_to_dist=node_to_dist, time_point=time_point\n",
    "        )\n",
    "    )\n",
    "    time_point_to_internal_nodes_to_parition_by = time_point_to_internal_nodes_to_parition_by.set_index(\"time_point\")[\n",
    "        \"nodes_to_partition_by\"\n",
    "    ].to_dict()\n",
    "    with open(time_points_to_partition_by_outpath, \"wb\") as outfile:\n",
    "        pickle.dump(obj=time_point_to_internal_nodes_to_parition_by, file=outfile)\n",
    "\n",
    "for time_point in time_points_to_partition_by:\n",
    "    print(\n",
    "        f\"# clades when partitioning by {time_point}M years = {len(time_point_to_internal_nodes_to_parition_by[time_point])}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ac8f278e-8843-42c8-b7a9-3d517cf6c14d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QA on time point 5\n",
      "QA on time point 10\n",
      "QA on time point 20\n"
     ]
    }
   ],
   "source": [
    "for time_point in time_points_to_partition_by:\n",
    "    print(f\"QA on time point {time_point}\")\n",
    "    for node_name in time_point_to_internal_nodes_to_parition_by[time_point]:\n",
    "        node = tree.search_nodes(name=node_name)[0]\n",
    "        node_age = node.get_distance(node.get_leaves()[0])\n",
    "        assert node_age <= time_point"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}